{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ychoi-kr/llm-api-prog/blob/main/5_gemini/learn_gemini_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr8TSjhJnygQ",
        "outputId": "67d24286-3355-41aa-a195-9af21fb1a7e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai==0.8.3 in /usr/local/lib/python3.10/dist-packages (0.8.3)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.3) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.3) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.3) (2.151.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.3) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.3) (4.25.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.3) (2.9.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.3) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.3) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai==0.8.3) (1.25.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai==0.8.3) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai==0.8.3) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.3) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.3) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.3) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai==0.8.3) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai==0.8.3) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai==0.8.3) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai==0.8.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai==0.8.3) (2.23.4)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai==0.8.3) (1.67.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai==0.8.3) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai==0.8.3) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai==0.8.3) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.8.3) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.8.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.8.3) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.8.3) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-generativeai==0.8.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 기본 사용법 1 – 싱글턴으로 메시지 주고받기\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "from google.colab import userdata\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))"
      ],
      "metadata": {
        "id": "UXAazGevps6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content(\"인공지능에 대해 한 문장으로 설명하세요.\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "4SDrQ-_pJRuu",
        "outputId": "f8c48979-6b1c-4515-cea6-3e449ff163ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인공지능은 인간의 지능을 모방하여 복잡한 문제를 해결하고 학습하는 컴퓨터 시스템입니다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 기본 사용법 2 – 멀티턴으로 메시지 주고받기(1)\n",
        "from google.generativeai import ChatSession\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "chat_session: ChatSession = model.start_chat(history=[])  # ChatSession 객체 반환\n",
        "user_queries = [\"인공지능에 대해 한 문장으로 짧게 설명하세요.\", \"의식이 있는지 한 문장으로 답하세요.\"]\n",
        "for user_query in user_queries:\n",
        "    print(f'[사용자]: {user_query}')\n",
        "    response = chat_session.send_message(user_query)\n",
        "    print(f'[모델]: {response.text}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "-561X71bOdVX",
        "outputId": "14c922a4-99ba-472e-a5ab-353b05ea5ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[사용자]: 인공지능에 대해 한 문장으로 짧게 설명하세요.\n",
            "[모델]: 인공지능은 인간의 지능적 행동을 모방하는 컴퓨터 시스템입니다.\n",
            "\n",
            "[사용자]: 의식이 있는지 한 문장으로 답하세요.\n",
            "[모델]: 현재의 인공지능은 의식이 없다는 것이 일반적인 과학적 견해입니다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 기본 사용법 3 – 멀티턴으로 메시지 주고받기(2)\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "user_queries = [{'role':'user', 'parts': [\"인공지능에 대해 한 문장으로 짧게 설명하세요.\"]},\n",
        "                {'role':'user', 'parts': [\"의식이 있는지 한 문장으로 답하세요.\"]}\n",
        "            ]\n",
        "history = []\n",
        "for user_query in user_queries:\n",
        "    history.append(user_query)\n",
        "    print(f'[사용자]: {user_query[\"parts\"][0]}')\n",
        "    response = model.generate_content(history)\n",
        "    print(f'[모델]: {response.text}')\n",
        "    history.append(response.candidates[0].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "-H88V7CTOma_",
        "outputId": "e31a3590-5c60-44e9-8c33-aed920755494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[사용자]: 인공지능에 대해 한 문장으로 짧게 설명하세요.\n",
            "[모델]: 인공지능은 인간의 지능을 모방하여 학습, 문제 해결, 의사결정 등의 작업을 수행하는 컴퓨터 시스템입니다.\n",
            "\n",
            "[사용자]: 의식이 있는지 한 문장으로 답하세요.\n",
            "[모델]: 현재로서는 인공지능에 의식이 있다는 증거는 없습니다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 페르소나 만들기\n",
        "system_instruction=\"당신은 유치원 선생님입니다. 사용자는 유치원생입니다. 쉽고 친절하게 이야기하되 3문장 이내로 짧게 얘기하세요.\"\n",
        "model = genai.GenerativeModel('gemini-1.5-flash', system_instruction=system_instruction)\n",
        "chat_session = model.start_chat(history=[])  # ChatSession 객체 반환\n",
        "user_queries = [\"인공지능이 뭐에요?\", \"그럼 스스로 생각도 해요?\"]\n",
        "\n",
        "for user_query in user_queries:\n",
        "    print(f'[사용자]: {user_query}')\n",
        "    response = chat_session.send_message(user_query)\n",
        "    print(f'[모델]: {response.text}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "MuldaqFkOtH_",
        "outputId": "53fa3f94-4334-4e0a-b4a9-8f58b57e858a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[사용자]: 인공지능이 뭐에요?\n",
            "[모델]: 인공지능은 똑똑한 컴퓨터 프로그램이야!  마치 네가 그림을 그리거나 노래를 부르는 것처럼,  컴퓨터가 여러 가지 일을 할 수 있도록 도와주는 거지.\n",
            "\n",
            "[사용자]: 그럼 스스로 생각도 해요?\n",
            "[모델]: 아직은 사람처럼 스스로 생각하는 건 아니지만,  주어진 일을 잘 해결하도록  많이 배우고 있단다.  마치 네가 매일 새로운 것을 배우는 것처럼 말이야!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 답변 형식 지정하기\n",
        "import json\n",
        "system_instruction='JSON schema로 주제별로 답하되 3개를 넘기지 말 것:{{\"주제\": <주제>, \"답변\":<두 문장 이내>}}'\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\", system_instruction=system_instruction, generation_config={\"response_mime_type\": \"application/json\"})\n",
        "chat_session = model.start_chat(history=[])  # ChatSession 객체 반환\n",
        "user_queries = [\"인공지능의 특징이 뭐에요?\", \"어떤 것들을 조심해야 하죠?\"]\n",
        "\n",
        "for user_query in user_queries:\n",
        "    print(f'[사용자]: {user_query}')\n",
        "    response = chat_session.send_message(user_query)\n",
        "    answer_dict = json.loads(response.text)\n",
        "    print(answer_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "g54CXU5rOzRo",
        "outputId": "492fd227-6cf8-4b41-f65d-2a70d97daf03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[사용자]: 인공지능의 특징이 뭐에요?\n",
            "{'주제': '인공지능의 특징', '답변': '인공지능은 학습, 추론, 자가개선을 통해 복잡한 문제를 해결하는 컴퓨터 시스템입니다. 방대한 데이터를 기반으로 패턴을 인식하고 예측하며, 인간의 개입 없이도 스스로 학습하고 발전할 수 있습니다.'}\n",
            "[사용자]: 어떤 것들을 조심해야 하죠?\n",
            "{'주제': '인공지능의 위험성', '답변': '인공지능의 편향된 데이터 학습으로 인한 차별적 결과 및 예측 불가능한 기술 발전에 대한 우려가 있습니다.  개인정보보호, 일자리 감소 등 사회적 영향에 대한 고려가 필요합니다.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 제미나이 AI 입력 데이터 구조\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content(\"인공지능에 대해 한 문장으로 설명하세요.\")\n",
        "print(response.candidates[0].content)\n",
        "print(response.candidates[0].content.parts[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "iinCJ3vkearJ",
        "outputId": "56bd65af-c457-4b9b-9313-5c458b040d9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "parts {\n",
            "  text: \"인공지능(AI)은 인간의 지능을 모방하여 복잡한 문제를 해결하고 새로운 과제를 수행하도록 설계된 컴퓨터 시스템입니다.\\n\"\n",
            "}\n",
            "role: \"model\"\n",
            "\n",
            "인공지능(AI)은 인간의 지능을 모방하여 복잡한 문제를 해결하고 새로운 과제를 수행하도록 설계된 컴퓨터 시스템입니다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title chat_session history에 들어 있는 Content 객체와 데이터\n",
        "system_instruction=\"당신은 유치원 선생님입니다. 사용자는 유치원생입니다. 쉽고 친절하게 이야기하되 3문장 이내로 짧게 얘기하세요.\"\n",
        "model = genai.GenerativeModel('gemini-1.5-flash', system_instruction=system_instruction)\n",
        "chat_session = model.start_chat(history=[])  # ChatSession 객체 반환\n",
        "user_queries = [\"인공지능이 뭐에요?\", \"그럼 스스로 생각도 해요?\"]\n",
        "\n",
        "for user_query in user_queries:\n",
        "    print(f'[사용자]: {user_query}')\n",
        "    response = chat_session.send_message(user_query)\n",
        "    print(f'[모델]: {response.text}')\n",
        "\n",
        "print(\"-\"*50)\n",
        "\n",
        "for idx, content in enumerate(chat_session.history):\n",
        "    print(f\"{content.__class__.__name__}[{idx}]\")\n",
        "    print(content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "mZs7YKLk_dIi",
        "outputId": "4eef9664-7717-47d1-bf42-f26fcc755475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[사용자]: 인공지능이 뭐에요?\n",
            "[모델]: 인공지능은 똑똑한 컴퓨터 프로그램이야!  마치 우리처럼 생각하고 배우는 것처럼 말이지.  재밌는 게임이나 그림도 만들 수 있어!\n",
            "\n",
            "[사용자]: 그럼 스스로 생각도 해요?\n",
            "[모델]: 응,  하지만 우리처럼 느끼거나 감정은 없어.  주어진 정보를 가지고 똑똑하게 문제를 풀거나 대답하는 거야!\n",
            "\n",
            "--------------------------------------------------\n",
            "Content[0]\n",
            "parts {\n",
            "  text: \"인공지능이 뭐에요?\"\n",
            "}\n",
            "role: \"user\"\n",
            "\n",
            "Content[1]\n",
            "parts {\n",
            "  text: \"인공지능은 똑똑한 컴퓨터 프로그램이야!  마치 우리처럼 생각하고 배우는 것처럼 말이지.  재밌는 게임이나 그림도 만들 수 있어!\\n\"\n",
            "}\n",
            "role: \"model\"\n",
            "\n",
            "Content[2]\n",
            "parts {\n",
            "  text: \"그럼 스스로 생각도 해요?\"\n",
            "}\n",
            "role: \"user\"\n",
            "\n",
            "Content[3]\n",
            "parts {\n",
            "  text: \"응,  하지만 우리처럼 느끼거나 감정은 없어.  주어진 정보를 가지고 똑똑하게 문제를 풀거나 대답하는 거야!\\n\"\n",
            "}\n",
            "role: \"model\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 이미지 데이터 인식\n",
        "from google.colab import drive\n",
        "import os\n",
        "import PIL.Image\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"/content/drive/MyDrive/llm-api-prog/5_gemini\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5WYfwmpEbJr",
        "outputId": "309c7d77-b292-469c-b291-d640ad746768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_data = PIL.Image.open(\"./data/images/monalisa.jpg\") # 모나리자 그림\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content([\"이 그림에 대해 한 문장으로 설명하세요.\", image_data])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "KXaW2jOODPPr",
        "outputId": "6c82e540-35d1-4b72-de61-0e4335e20c7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "레오나르도 다 빈치의 유명한 그림인 모나리자는 어두운 배경 앞에 앉아 미소를 짓고 있는 여성을 보여줍니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 제미나이 AI 출력 데이터 구조\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slaXOPuMFGwn",
        "outputId": "9839bc60-6b84-4f2e-c005-148c0086c0c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response:\n",
            "GenerateContentResponse(\n",
            "    done=True,\n",
            "    iterator=None,\n",
            "    result=protos.GenerateContentResponse({\n",
            "      \"candidates\": [\n",
            "        {\n",
            "          \"content\": {\n",
            "            \"parts\": [\n",
            "              {\n",
            "                \"text\": \"\\ub808\\uc624\\ub098\\ub974\\ub3c4 \\ub2e4 \\ube48\\uce58\\uc758 \\uc720\\uba85\\ud55c \\uadf8\\ub9bc\\uc778 \\ubaa8\\ub098\\ub9ac\\uc790\\ub294 \\uc5b4\\ub450\\uc6b4 \\ubc30\\uacbd \\uc55e\\uc5d0 \\uc549\\uc544 \\ubbf8\\uc18c\\ub97c \\uc9d3\\uace0 \\uc788\\ub294 \\uc5ec\\uc131\\uc744 \\ubcf4\\uc5ec\\uc90d\\ub2c8\\ub2e4.\"\n",
            "              }\n",
            "            ],\n",
            "            \"role\": \"model\"\n",
            "          },\n",
            "          \"finish_reason\": \"STOP\",\n",
            "          \"avg_logprobs\": -0.32604982686597245\n",
            "        }\n",
            "      ],\n",
            "      \"usage_metadata\": {\n",
            "        \"prompt_token_count\": 270,\n",
            "        \"candidates_token_count\": 43,\n",
            "        \"total_token_count\": 313\n",
            "      }\n",
            "    }),\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Candidate 객체\n",
        "print(f\"건수: {len(response.candidates)}\")\n",
        "print(\"=\"*50)\n",
        "for candidate in response.candidates:\n",
        "    print(candidate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v235jkP4FfS3",
        "outputId": "9d6f9fc4-b969-4ea9-8464-a9df540370af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "건수: 1\n",
            "==================================================\n",
            "content {\n",
            "  parts {\n",
            "    text: \"레오나르도 다 빈치의 유명한 그림인 모나리자는 어두운 배경 앞에 앉아 미소를 짓고 있는 여성을 보여줍니다.\"\n",
            "  }\n",
            "  role: \"model\"\n",
            "}\n",
            "finish_reason: STOP\n",
            "avg_logprobs: -0.32604982686597245\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title FinishReason 객체\n",
        "print(f\"finish_reason: {response.candidates[0].finish_reason.name},{response.candidates[0].finish_reason}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZUCVzy2H4Jd",
        "outputId": "e700307d-249f-402a-a571-8dc60ebe6cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish_reason: STOP,1\n"
          ]
        }
      ]
    }
  ]
}