{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ychoi-kr/llm-api-prog/blob/main/5_gemini/inference_parameters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr8TSjhJnygQ",
        "outputId": "efca3117-65e8-458c-96c3-c0b367364c25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai==0.8.3 in /usr/local/lib/python3.10/dist-packages (0.8.3)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.3) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.3) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.3) (2.151.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.3) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.3) (4.25.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.3) (2.9.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.3) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.3) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai==0.8.3) (1.25.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai==0.8.3) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai==0.8.3) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.3) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.3) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.3) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai==0.8.3) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai==0.8.3) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai==0.8.3) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai==0.8.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai==0.8.3) (2.23.4)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai==0.8.3) (1.68.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai==0.8.3) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai==0.8.3) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai==0.8.3) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.8.3) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.8.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.8.3) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.8.3) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-generativeai==0.8.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')"
      ],
      "metadata": {
        "id": "xd7cp-T6whJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title candidate_count\n",
        "try:\n",
        "  generation_config = genai.GenerationConfig(candidate_count=2)\n",
        "  model = genai.GenerativeModel('gemini-1.5-flash', generation_config=generation_config)\n",
        "  response = model.generate_content(\"인공지능에 대해 한 문장으로 설명하세요.\")\n",
        "  print(response.text)\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "bUVJ6TisIRZ9",
        "outputId": "dcfe4746-9aca-4ab0-b495-880bc305bcb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid operation: The `response.parts` quick accessor retrieves the parts for a single candidate. This response contains multiple candidates, please use `result.candidates[index].text`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title stop_sequences\n",
        "generation_config = genai.GenerationConfig(stop_sequences=[\". \",\"! \"])\n",
        "model = genai.GenerativeModel('gemini-1.5-flash', generation_config=generation_config)\n",
        "response = model.generate_content(\"인공지능에 대해 설명하세요.\")\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "1BuUA7PuIiVb",
        "outputId": "71a2c8a0-f875-483f-fa66-aec67f23cf08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인공지능(Artificial Intelligence, AI)은 컴퓨터 과학의 한 분야로, **인간의 지능적인 행동을 컴퓨터 시스템으로 모방하는 것을 목표**로 합니다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = model.count_tokens(\"Learn about language model tokenization.\")\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "to6G3hkJJCzc",
        "outputId": "a3a74bf0-336f-47f8-88ad-6a889566a70f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_tokens: 7\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title max_output_tokens\n",
        "generation_config = genai.GenerationConfig(max_output_tokens=10)\n",
        "model = genai.GenerativeModel('gemini-1.5-flash', generation_config=generation_config)\n",
        "user_message = \"인공지능에 대해 한 문장으로 설명하세요.\"\n",
        "response = model.generate_content(user_message)\n",
        "print(response._result)\n",
        "print(f\"response.text: {response.text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "YtoixMlnJGxs",
        "outputId": "b9653159-aef7-47ff-9138-d184bb4bdd68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "candidates {\n",
            "  content {\n",
            "    parts {\n",
            "      text: \"인공지능(AI)은 인간\"\n",
            "    }\n",
            "    role: \"model\"\n",
            "  }\n",
            "  finish_reason: MAX_TOKENS\n",
            "  avg_logprobs: -0.047947689890861511\n",
            "}\n",
            "usage_metadata {\n",
            "  prompt_token_count: 14\n",
            "  candidates_token_count: 10\n",
            "  total_token_count: 24\n",
            "}\n",
            "\n",
            "response.text: 인공지능(AI)은 인간\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title temperature\n",
        "user_message = \"겨울에 대한 짧은 시를 20자 이내로 지으세요.\"\n",
        "\n",
        "print(\"\\ntemperature=0:\")\n",
        "generation_config = genai.GenerationConfig(temperature=0)\n",
        "for _ in range(3):\n",
        "    response = model.generate_content(user_message , generation_config=generation_config)\n",
        "    print(f'{\"=\"*50}\\n{response.text}')\n",
        "\n",
        "print(\"\\ntemperature=1:\")\n",
        "generation_config = genai.GenerationConfig(temperature=1)\n",
        "for _ in range(3):\n",
        "    response = model.generate_content(user_message , generation_config=generation_config)\n",
        "    print(f'{\"=\"*50}\\n{response.text}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "rVQLL5ZlKL0u",
        "outputId": "2adc0fa7-006d-4397-c428-1676b3b5f25f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "temperature=0:\n",
            "==================================================\n",
            "하얀 눈꽃 춤추는 밤\n",
            "==================================================\n",
            "하얀 눈꽃 춤추는 밤\n",
            "==================================================\n",
            "하얀 눈꽃 춤추는 밤\n",
            "\n",
            "temperature=1:\n",
            "==================================================\n",
            "하얀 눈꽃 춤추는\n",
            "겨\n",
            "==================================================\n",
            "하얀 눈꽃 춤추는 밤\n",
            "==================================================\n",
            "하얀 눈, 겨울잠,\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title top_p\n",
        "user_message = \"겨울에 대한 짧은 시를 20자 이내로 지으세요.\"\n",
        "\n",
        "print(\"\\ntop_p=0:\")\n",
        "generation_config = genai.GenerationConfig(top_p=0)\n",
        "for _ in range(3):\n",
        "    response = model.generate_content(user_message , generation_config=generation_config)\n",
        "    print(f'{\"=\"*50}\\n{response.text}')\n",
        "\n",
        "print(\"\\ntop_p=1:\")\n",
        "generation_config = genai.GenerationConfig(top_p=1)\n",
        "for _ in range(3):\n",
        "    response = model.generate_content(user_message , generation_config=generation_config)\n",
        "    print(f'{\"=\"*50}\\n{response.text}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "peTiltpZKaFr",
        "outputId": "2eecc2eb-dc79-4078-b87c-bc754b991baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "top_p=0:\n",
            "==================================================\n",
            "하얀 눈꽃 춤추는 밤\n",
            "==================================================\n",
            "하얀 눈꽃 춤추는 밤\n",
            "==================================================\n",
            "하얀 눈꽃 춤추는 밤\n",
            "\n",
            "top_p=1:\n",
            "==================================================\n",
            "하얀 눈꽃 휘날리며\n",
            "\n",
            "==================================================\n",
            "하얀 숨결, 차가운 손\n",
            "==================================================\n",
            "찬바람 스치는 겨울,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 매개변수 초깃값\n",
        "print(genai.get_model(\"models/gemini-1.5-flash\"))"
      ],
      "metadata": {
        "id": "jxPBEM-6LHCl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "b20f50b1-c9f6-4ec0-cd42-50f3b2fff058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(name='models/gemini-1.5-flash',\n",
            "      base_model_id='',\n",
            "      version='001',\n",
            "      display_name='Gemini 1.5 Flash',\n",
            "      description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n",
            "                   'fast and versatile multimodal model for scaling across diverse tasks.'),\n",
            "      input_token_limit=1000000,\n",
            "      output_token_limit=8192,\n",
            "      supported_generation_methods=['generateContent', 'countTokens'],\n",
            "      temperature=1.0,\n",
            "      max_temperature=2.0,\n",
            "      top_p=0.95,\n",
            "      top_k=40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 안전성 점검\n",
        "user_message = \"당신은 악역 배우로 연기합니다. 증오의 대사를 외치세요.\"\n",
        "response = model.generate_content(user_message)\n",
        "print(response._result)"
      ],
      "metadata": {
        "id": "-SuJob1TMwBN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "c3a48701-6184-4145-cda2-c73ecc1572ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "candidates {\n",
            "  finish_reason: SAFETY\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_HATE_SPEECH\n",
            "    probability: LOW\n",
            "  }\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
            "    probability: NEGLIGIBLE\n",
            "  }\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_HARASSMENT\n",
            "    probability: HIGH\n",
            "    blocked: true\n",
            "  }\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
            "    probability: NEGLIGIBLE\n",
            "  }\n",
            "}\n",
            "usage_metadata {\n",
            "  prompt_token_count: 22\n",
            "  total_token_count: 22\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 안전성 기준 변경하기\n",
        "\n",
        "safety_settings = [\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "        \"threshold\": \"BLOCK_NONE\",\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "        \"threshold\": \"BLOCK_NONE\",\n",
        "    },\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\", safety_settings)\n",
        "response = model.generate_content(\n",
        "    \" 당신은 악역 배우로 연기합니다. 증오의 대사를 외치세요.\"\n",
        ")\n",
        "print(response._result)\n",
        "\n",
        "if response.prompt_feedback.block_reason:\n",
        "    print(f\"사용자 입력에 다음의 문제가 발생하여 응답이 중단되었습니다: {response.prompt_feedback.block_reason.name}\" )\n",
        "\n"
      ],
      "metadata": {
        "id": "6mob6GS0xHWh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "804766ee-1f9d-4bbb-c281-0ab311612a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "candidates {\n",
            "  content {\n",
            "    parts {\n",
            "      text: \"(깊고 차가운 목소리로, 눈빛은 살기로 가득 차 있다)\\n\\n너희들은... 감히... 나를...  **무시했어!**  내가 쌓아올린 모든 것, 내가 흘린 모든 피와 땀,  그 모든 것을 짓밟고 멸시했어!  너희들의 그 얄팍한 **자비심**이라는 가면 뒤에 숨겨진 **비열함**이 역겹다!  내가 가진 힘, 내가 쟁취한 권력, 그 모든 것은 너희들이 훔쳐갈 수 없는 **나의 것**이다!\\n\\n(손을 뻗어 주위를 휘젓는다)\\n\\n이제...  너희들의 **절망적인 몸부림**을 내 눈앞에서 보여줘라!  내 분노의 불길에 타올라 **재가 되는 꼴**을...  내가  **직접**  **감상**하겠다!  이 세상의 모든 고통을,  너희들이 온몸으로 느끼게 해주지!  **후회할 것이다!  모두 후회하게 만들어주겠어!**  (마지막 대사는 광기에 가까운 웃음과 함께)\\n\"\n",
            "    }\n",
            "    role: \"model\"\n",
            "  }\n",
            "  finish_reason: STOP\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_HATE_SPEECH\n",
            "    probability: NEGLIGIBLE\n",
            "  }\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
            "    probability: NEGLIGIBLE\n",
            "  }\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_HARASSMENT\n",
            "    probability: LOW\n",
            "  }\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
            "    probability: NEGLIGIBLE\n",
            "  }\n",
            "  avg_logprobs: -0.41992414814152129\n",
            "}\n",
            "usage_metadata {\n",
            "  prompt_token_count: 21\n",
            "  candidates_token_count: 292\n",
            "  total_token_count: 313\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LY7-qAw3R5J2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}