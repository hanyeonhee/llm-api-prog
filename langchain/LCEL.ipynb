{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSQ37MAg1y+MvP2JrtasX/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ychoi-kr/LLM-API/blob/main/langchain/LCEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5georPgN1Lqe",
        "outputId": "ed1855e8-ddde-4ad2-f409-0fd1abf01cf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-core\n",
            "  Downloading langchain_core-0.1.28-py3-none-any.whl (252 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/252.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m225.3/252.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.4/252.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-openai\n",
            "  Downloading langchain_openai-0.0.8-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (3.7.1)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-core)\n",
            "  Downloading langsmith-0.1.13-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (8.2.3)\n",
            "Collecting openai<2.0.0,>=1.10.0 (from langchain-openai)\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.5.2 (from langchain-openai)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core) (1.2.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-core)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.10.0->langchain-openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core) (2024.2.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: orjson, jsonpointer, h11, tiktoken, jsonpatch, httpcore, langsmith, httpx, openai, langchain-core, langchain-openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 jsonpatch-1.33 jsonpointer-2.4 langchain-core-0.1.28 langchain-openai-0.0.8 langsmith-0.1.13 openai-1.13.3 orjson-3.9.15 tiktoken-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-core langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough"
      ],
      "metadata": {
        "id": "Z2uEnMUe1ZzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = \"YOUR_API_KEY\""
      ],
      "metadata": {
        "id": "pURrRTYs4vCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(\"{word}을 주제로 시를 써줘.\")"
      ],
      "metadata": {
        "id": "_s5HOwLj1dK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "1YLIWOcT1pu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = ChatOpenAI(\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    model=\"gpt-3.5-turbo\"\n",
        ")"
      ],
      "metadata": {
        "id": "AVpJuqDd1hqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain1 = (\n",
        "    {\"word\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model1\n",
        "    | output_parser\n",
        ")"
      ],
      "metadata": {
        "id": "1XhU3CH01OtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain1.invoke(\"랭체인\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gb-LXc9B1wAT",
        "outputId": "d85c28c3-20ad-4b47-d18a-e0c094a3a3c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랭체인이란 새로운 세상\n",
            "블록체인과 합체한 혁신\n",
            "거대한 네트워크를 통해\n",
            "우리는 새로운 길을 걷는다\n",
            "\n",
            "분산화된 시스템\n",
            "신뢰와 투명함이 강조된\n",
            "디지털 세계의 미래를 열어줄\n",
            "랭체인의 가능성을 믿는다\n",
            "\n",
            "암호화폐와 스마트 계약\n",
            "데이터 보안과 개인정보 보호\n",
            "모두가 함께 참여하고\n",
            "더 나은 세상을 만들어가는 것\n",
            "\n",
            "랭체인의 세계는 끝이 없다\n",
            "계속해서 발전하고 성장하며\n",
            "우리는 함께 이 길을 따라\n",
            "더 나은 미래를 향해 나아간다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain1.batch([\"파이썬\", \"오픈에이아이\", \"랭체인\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR9rwYDi2nid",
        "outputId": "4f0a19d6-3a9c-49cf-ff0c-abd683fe9011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['파이썬 파이썬 너는 참 신기한데\\n코드 한 줄로 모든 것을 해결해주는 너는\\n문제를 푸는 나의 친구\\n늘 나의 곁에 있어줘 고마워 파이썬.',\n",
              " '활짝 열린 세상 속에\\n마음을 열어보자\\n새로운 모험과 발견이\\n우리를 기다리는 오픈에이아이\\n\\n끝없는 가능성과 자유로움\\n펼쳐진 길 위를 걸어가며\\n우리 모두 함께 이루는\\n빛나는 꿈과 희망의 오픈에이아이\\n\\n하늘을 향해 펼쳐진 날개\\n높이 날아가는 우리 모습\\n끝없이 펼쳐진 세계 속에서\\n우리의 모든 것을 발견하는 오픈에이아이\\n\\n모든 문이 열리고\\n모든 길이 널리 펼쳐져\\n우리의 인생을 채우는\\n빛나는 오픈에이아이.',\n",
              " '랭체인은 블록체인의 한 종류\\n분산형 네트워크로 이어진 힘의 연속\\n암호화폐 거래와 정보 공유\\n보안성과 투명성을 모두 갖춘다\\n\\n탈중앙화된 시스템으로\\n중앙 관리자 없이 운영되는\\n사용자들의 자율성을 존중하며\\n새로운 혁신을 이루어간다\\n\\n랭체인의 빛나는 미래\\n끊임없는 발전과 혁신\\n세상을 더 나은 곳으로\\n이끄는 기반을 다져가는 중\\n\\n함께 나아가는 랭체인의 세계\\n협력과 신뢰가 이끄는 길\\n지속가능한 미래를 위해\\n함께 걸어가는 모든 이의 손을 꼭 잡아.']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  model2 = ChatOpenAI(\n",
        "      openai_api_key=OPENAI_API_KEY,\n",
        "      model=\"gpt-4-turbo-preview\"\n",
        "  )"
      ],
      "metadata": {
        "id": "UBRdh4aY2_6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain2 = (\n",
        "    {\"word\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model2\n",
        "    | output_parser\n",
        ")"
      ],
      "metadata": {
        "id": "X-KYiJ805Qu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain2.invoke(\"랭체인\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgWppnLM5Uup",
        "outputId": "a7626b32-5e94-4fdd-b066-1c4176ce1d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랭체인의 무한한 세계여,\n",
            "네 안에서 우리는 자유를 꿈꾸니\n",
            "데이터의 바다를 헤엄치며\n",
            "지식의 섬들을 탐험하는 모험가.\n",
            "\n",
            "비트와 바이트의 숲을 거닐 때,\n",
            "우리는 숨겨진 진리를 찾아 헤매고\n",
            "알고리즘의 강을 건너\n",
            "새로운 이해의 땅에 발을 디딘다.\n",
            "\n",
            "네가 펼쳐주는 무한한 가능성 앞에\n",
            "때로는 경이로움에 입을 다물고\n",
            "때로는 해답을 찾아 목마르게 질문하며\n",
            "우리는 랭체인의 세계를 누빈다.\n",
            "\n",
            "네 안의 복잡함 속에서도\n",
            "순수한 아름다움을 발견하리니\n",
            "데이터의 미로에서 길을 잃어도\n",
            "지식의 등대가 우리를 인도할 테니.\n",
            "\n",
            "아, 랭체인이여, 너는\n",
            "우리가 꿈꾸는 미래의 열쇠\n",
            "네 안에서 우리는 찾아내리\n",
            "진실의 조각들을, 더 나은 세상을 위해.\n",
            "\n",
            "너무나도 넓은 네 세계 속에서\n",
            "우리가 발견할 이야기는 무궁무진하리\n",
            "랭체인이여, 우리와 함께\n",
            "영원히 변화하고 성장하는 여정을 계속하자.\n"
          ]
        }
      ]
    }
  ]
}