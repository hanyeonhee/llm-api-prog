{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ychoi-kr/LLM-API/blob/main/langchain/langchain_chatupstage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if12XvBDETiK"
      },
      "source": [
        "# LangChain과 솔라 API를 활용한 간단한 질의응답 및 채팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JevgVhdIxo5w",
        "outputId": "8775f179-e39b-48d7-ba5a-1305ef90dff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-upstage\n",
            "  Downloading langchain_upstage-0.1.0-py3-none-any.whl (6.8 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.44 (from langchain-upstage)\n",
            "  Downloading langchain_core-0.1.44-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-openai<0.2.0,>=0.1.3 (from langchain-upstage)\n",
            "  Downloading langchain_openai-0.1.3-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.44->langchain-upstage) (6.0.1)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.44->langchain-upstage)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-core<0.2.0,>=0.1.44->langchain-upstage)\n",
            "  Downloading langsmith-0.1.49-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.44->langchain-upstage)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.44->langchain-upstage) (2.7.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.44->langchain-upstage) (8.2.3)\n",
            "Collecting openai<2.0.0,>=1.10.0 (from langchain-openai<0.2.0,>=0.1.3->langchain-upstage)\n",
            "  Downloading openai-1.23.1-py3-none-any.whl (310 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.0/311.0 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.5.2 (from langchain-openai<0.2.0,>=0.1.3->langchain-upstage)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.44->langchain-upstage)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.44->langchain-upstage)\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m945.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.44->langchain-upstage) (2.31.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai<0.2.0,>=0.1.3->langchain-upstage) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai<0.2.0,>=0.1.3->langchain-upstage) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.10.0->langchain-openai<0.2.0,>=0.1.3->langchain-upstage)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai<0.2.0,>=0.1.3->langchain-upstage) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai<0.2.0,>=0.1.3->langchain-upstage) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai<0.2.0,>=0.1.3->langchain-upstage) (4.11.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.44->langchain-upstage) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.44->langchain-upstage) (2.18.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai<0.2.0,>=0.1.3->langchain-upstage) (2023.12.25)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai<0.2.0,>=0.1.3->langchain-upstage) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai<0.2.0,>=0.1.3->langchain-upstage) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai<0.2.0,>=0.1.3->langchain-upstage) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai<0.2.0,>=0.1.3->langchain-upstage)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai<0.2.0,>=0.1.3->langchain-upstage)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.44->langchain-upstage) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.44->langchain-upstage) (2.0.7)\n",
            "Installing collected packages: packaging, orjson, jsonpointer, h11, tiktoken, jsonpatch, httpcore, langsmith, httpx, openai, langchain-core, langchain-openai, langchain-upstage\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonpatch-1.33 jsonpointer-2.4 langchain-core-0.1.44 langchain-openai-0.1.3 langchain-upstage-0.1.0 langsmith-0.1.49 openai-1.23.1 orjson-3.10.1 packaging-23.2 tiktoken-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-core==0.2.41 langchain==0.2.16 langchain-openai==0.1.23 langchain-upstage==0.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Sl9bnj4euGl0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['UPSTAGE_API_KEY'] = userdata.get('UPSTAGE_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wqB5bKwWxgzr"
      },
      "outputs": [],
      "source": [
        "from langchain_upstage import ChatUpstage\n",
        "chat = ChatUpstage()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGW0YrHV2S7x"
      },
      "source": [
        "## 기억력이 없는 챗봇"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQJ4Bnbvx_8X",
        "outputId": "5a640c3a-8f04-4255-c31c-afff48db0014"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "멋진 일이네요! LLM API 활용법을 알려주는 책을 쓰시는 건가요? 어떤 내용을 다루고 싶으신가요? 제가 도움을 드릴 수 있는 부분이 있다면 언제든지 말씀해주세요!\n"
          ]
        }
      ],
      "source": [
        "message = chat.invoke(\"나는 LLM API 활용법을 알려주는 책을 쓰고 있어.\")\n",
        "print(message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5rFe13pyVk2",
        "outputId": "9ad80d50-750d-490f-baec-48f1474accff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "책의 제목은 그 책의 내용을 잘 나타내야 합니다. 책의 주제와 내용을 고려하여 적절한 제목을 선택해보세요. 몇 가지 아이디어를 드리자면:\n",
            "\n",
            "1. \"마법의 숲 탐험: 판의 미로\"\n",
            "2. \"판과 함께하는 모험: 마법의 세계\"\n",
            "3. \"판의 미로: 신비로운 숲의 비밀\"\n",
            "4. \"마법의 숲을 찾아서: 판의 모험 이야기\"\n",
            "5. \"판과 함께하는 환상의 여행: 마법의 숲\"\n",
            "\n",
            "이런 식으로 책의 내용과 분위기를 잘 반영하는 제목을 선택해보세요. 제목은 독자들의 관심을 끌고 책을 선택하고 싶어하게 만들 수 있는 중요한 요소입니다.\n"
          ]
        }
      ],
      "source": [
        "message = chat.invoke(\"책 제목이 뭐가 좋을까?\")\n",
        "print(message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CS3UFi7ys-5"
      },
      "source": [
        "## 대화 내용 기억하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hMHq7u1OzwW_"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwSpoyj_0H7t",
        "outputId": "068c7eb9-bac6-4288-b857-82d51ba4290b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "와, 그것은 매우 흥미로워 보입니다! LLM API 활용법에 대한 책을 쓰는 것은 매우 유용한 일이라고 생각합니다. 어떤 내용을 다룰 계획이신가요? LLM API에 대해 자세히 알려주실 수 있나요?\n"
          ]
        }
      ],
      "source": [
        "conversation = ConversationChain(\n",
        "    llm=chat,\n",
        "    memory=ConversationBufferMemory()\n",
        ")\n",
        "\n",
        "output = conversation.invoke(\"나는 LLM API 활용법을 알려주는 책을 쓰고 있어.\")\n",
        "print(output[\"response\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E08cQvLG0tHd",
        "outputId": "4039b29c-f374-4473-c973-95e0a2f2ec67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI: 좋은 책 제목은 독자들의 관심을 끌고 내용을 잘 반영하는 것이 중요합니다. 몇 가지 아이디어를 제안해 드릴게요:\n",
            "\n",
            "1. \"LLM API 마스터: 실용적인 활용법\"\n",
            "2. \"LLM API 완벽 가이드: 효과적인 활용을 위한 실전 전략\"\n",
            "3. \"LLM API로 여는 새로운 세계: 무한한 가능성의 문\"\n",
            "4. \"LLM API 정복: 전문가로 거듭나기 위한 완벽한 안내서\"\n",
            "\n",
            "이 중에서 마음에 드는 제목이 있으신가요? 아니면 더 많은 아이디어를 원하시면 말씀해주세요!\n"
          ]
        }
      ],
      "source": [
        "output = conversation.invoke(\"책 제목이 뭐가 좋을까?\")\n",
        "print(output[\"response\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOZp0Tfe/ZobFPy75I4XhlW",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
